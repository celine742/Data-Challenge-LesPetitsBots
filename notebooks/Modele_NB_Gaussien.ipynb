{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cb6c7c",
   "metadata": {},
   "source": [
    "# Modèle de classification bayésienne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7159d45",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd275ec",
   "metadata": {},
   "source": [
    "### Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b635d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des modules nécessaires\n",
    "import nltk\n",
    "import re\n",
    "import time\n",
    "import seaborn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import simplemma as sp  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Téléchargement des modules de nltk nécessaires\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac61c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simplemma | pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données\n",
    "data = pd.read_excel(\"../talks_complet.xlsx\")\n",
    "\n",
    "# Classification binaire des tag\n",
    "data['tag'].mask(data['tag'] == 'negative', 0, inplace=True)\n",
    "data['tag'].mask(data['tag'] == 'positive', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ec96e",
   "metadata": {},
   "source": [
    "### Pré-traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des messages en minuscule et suppression des accents\n",
    "x_lowered = [text.lower() for text in data[\"query\"]]\n",
    "x_lowered = [unidecode(text) for text in data[\"query\"]]\n",
    "\n",
    "print(x_lowered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab22b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation par mot\n",
    "x_tokenized = [nltk.word_tokenize(text) for text in x_lowered]\n",
    "\n",
    "print(x_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "x_lemmatized = [[sp.lemmatize((word), lang=('fr')) for word in text] for text in x_tokenized]\n",
    "\n",
    "print(x_lemmatized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba521074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"french\")\n",
    "x_prepared = [[word for word in text if word not in stopwords] for text in x_lemmatized]\n",
    "\n",
    "print(x_prepared[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db22683b",
   "metadata": {},
   "source": [
    "### Vectorisation par Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisation\n",
    "vectorizer = CountVectorizer(max_features=20000)\n",
    "doc = [\" \".join(v) for v in x_prepared]\n",
    "x = vectorizer.fit_transform(doc).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb755d",
   "metadata": {},
   "source": [
    "### Création et entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation en un training set et un testing set\n",
    "x_train,x_test,y_train,y_test  = train_test_split(x, np.asarray(data[\"tag\"]), random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed06e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "NB = GaussianNB()\n",
    "y_train=y_train.astype('int')\n",
    "NB.fit(x_train,y_train)\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30e392",
   "metadata": {},
   "source": [
    "### Prédiction et métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56687ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean accuracy\n",
    "NB.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e70555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction \n",
    "y_pred = NB.predict(x_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "conf = confusion_matrix(y_pred=y_pred,y_true=y_test)\n",
    "palette = seaborn.cubehelix_palette(n_colors=4, start=0, rot=0.4, gamma=1.0, hue=0.8, light=0.85, dark=0.15, reverse=False, as_cmap=False)\n",
    "seaborn.heatmap(conf,annot=True,fmt=\".1f\",linewidths=1.5, cbar=True, cmap=palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26053f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Précision, rappel et f-score\n",
    "precision_recall_fscore_support(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299319ae",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle et du vectorizer\n",
    "with open(\"model.pckl\",mode=\"wb\") as F:\n",
    "    pickle.dump(NB,F)\n",
    "    \n",
    "with open(\"vectorizer.pckl\",mode=\"wb\") as F:\n",
    "    pickle.dump(vectorizer,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198144a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prédiction\n",
    "def predict_anonymize(message):\n",
    "    \n",
    "    model = pickle.load(open(\"model.pckl\",mode=\"rb\"))\n",
    "    vectorizer = pickle.load(open(\"vectorizer.pckl\",mode=\"rb\"))\n",
    "    \n",
    "    message = unidecode(message)\n",
    "    stopwords = nltk.corpus.stopwords.words('french')\n",
    "    \n",
    "    message = message.lower()\n",
    "    message = nltk.word_tokenize(message)\n",
    "    message = [word for word in message if word not in stopwords]\n",
    "    message = \" \".join(message)\n",
    "    \n",
    "    vector = vectorizer.transform([message])\n",
    "    decision = model.predict(vector.toarray())\n",
    "    \n",
    "    return decision[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccafbe",
   "metadata": {},
   "source": [
    "### Test de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80001314",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_anonymize(\"quels sont les horaires du festival ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
